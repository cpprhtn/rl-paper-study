## 8th Study Paper List

Date | Paper | Presenter | Links
:---: | :---: | :---: | :---:
5/23 | Mutual Information State Intrinsic Control, R. Zhao et al, 2021. | Mark Young | [[paper]](https://arxiv.org/abs/2103.08107) [[review]](https://hugrypiggykim.com/2022/05/10/music-mutual-information-state-intrinsic-control/)
5/23 | A Reinforcement Learning Algorithm for The 2D-rectangular Strip Packing Problem, X. Zhao et al, 2022. | Taejun Park | [[paper]](https://iopscience.iop.org/article/10.1088/1742-6596/2181/1/012002) [[review]](./220523%20-%20A%20Reinforcement%20Learning%20Algorithm%20for%20The%202D-rectangular%20Strip%20Packing%20Problem%2C%20X.%20Zhao%20et%20al%2C%202022.pdf)
5/30 | Explainable Reinforcement Learning: A Survey, E. Puiutta et al, 2020. | Doyun Kim | [[paper]](https://arxiv.org/abs/2005.06247) [[review]](./220530%20-%20Explainable%20Reinforcement%20Learning%2C%20A%20Survey%2C%20E.%20Puiutta%20et%20al%2C%202020.pdf)
5/30 | Implicit Distributional Reinforcement Learning, Y. Yue et al, 2020. | Seungeon Baek | [[paper]](https://arxiv.org/abs/2007.06159) [[review]](./220530%20-%20Implicit%20Distributional%20Reinforcement%20Learning%2C%20Y.%20Yue%20et%20al%2C%202020.pdf)
6/13 | Offline Reinforcement Learning as One Big Sequence Modeling Problem, M. Janner et al, 2021. | Seungje Yoon | [[paper]](https://arxiv.org/abs/2106.02039) [[review]](./220613%20-%20Offline%20Reinforcement%20Learning%20as%20One%20Big%20Sequence%20Modeling%20Problem%2C%20M.%20Janner%20et%20al%2C%202021.pdf)
6/13 | Optimization of Global Production Scheduling with Deep Reinforcement Learning, B. Waschneck et al, 2018. | Yonghae Kim | [[paper]](https://www.sciencedirect.com/science/article/pii/S221282711830372X) [[review]](./220613%20-%20Optimization%20of%20Global%20Production%20Scheduling%20with%20Deep%20Reinforcement%20Learning%2C%20B.%20Waschneck%20et%20al%2C%202018.pdf)
6/20 | On Learning Intrinsic Rewards for Policy Gradient Methods, Z. Zheng et al, 2018. | Daejin Jo | [[paper]](https://arxiv.org/abs/1804.06459) [review]
6/20 | Implementation of Implicit Distributional Reinforcement Learning, Y. Yue et al, 2020. | Seungeon Baek | [[paper]](https://arxiv.org/abs/2007.06159) [code]
6/27 | Implementation of Battlesnake Challenge: A Multi-agent Reinforcement Learning Playground with Human-in-the-loop | Dohyun Kim | [[paper]](https://arxiv.org/abs/2007.10504) [code]
6/27 | Molecular De-novo Design through Deep Reinforcement Learning, M. Olivecrona et al, 2017. | Beomsuk Park | [[paper]](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-017-0235-x) [review]
7/4 | Magnetic Control of Tokamak Plasmas through Deep Reinforcement Learning, J. Degrave et al, 2022. | Jinsoo Kim | [[paper]](https://www.nature.com/articles/s41586-021-04301-9) [review]
7/4 | Sub-policy Adaptation for Hierarchical Reinforcement Learning, AC. Li et al, 2019. | Seonghak Hong | [[paper]](https://arxiv.org/abs/1906.05862) [review]
7/11 | A Generalist Agent, S. Reed et al, 2022. | Dokyoon Yoon | [[paper]](https://arxiv.org/abs/2205.06175) [review]
7/11 | Implementation of Phasic Policy Gradient, K. Cobbe et al, 2020. | Sungkwon On | [[paper]](https://arxiv.org/abs/2009.04416) [code]
7/18 | Implementation of IPDALight: Intensity- and Phase Duration-aware Traffic Signal Control based on Reinforcement Learning, W. Zhao et al, 2021. | Jiho Yeo | [[paper]](https://www.sciencedirect.com/science/article/abs/pii/S1383762121002587) [code]
7/18 | Development and Validation of a Reinforcement Learning Algorithm to Dynamically Optimize Mechanical Ventilation in Critical Care, A. Peine et al, 2021. | Hyeonhoon Lee | [[paper]](https://www.nature.com/articles/s41746-021-00388-6) [review]
7/25 | Implementation of Addressing Function Approximation Error in Actor-Critic Methods, S. Fujimoto et al, 2018. | Donggu Kang | [[paper]](https://arxiv.org/abs/1802.09477) [code]
7/25 | Language Understanding for Text-based Games Using Deep Reinforcement Learning, K. Narasimhan et al, 2015. | Sohyeon Yim | [[paper]](https://arxiv.org/abs/1506.08941) [review]
TBD | Implementation of Rainbow: Combining Improvements in Deep Reinforcement Learning, M. Hessel et al, 2017. | Chris Ohk | [[paper]](https://arxiv.org/abs/1710.02298) [code]

### Study Member

* [Chris Ohk](http://www.github.com/utilForever)
* [Mark Young](http://www.github.com/tylee33)
* Taejun Park
* [Doyun Kim](http://www.github.com/qelloman)
* [Seungeon Baek](http://www.github.com/SeungeonBaek)
* Yonghae Kim
* [Daejin Jo](http://www.github.com/twidddj)
* [Seungje Yoon](http://www.github.com/sjYoondeltar)
* [Dohyun Kim](http://www.github.com/kimdo331)
* Beomsuk Park
* Jinsoo Kim
* [Seonghak Hong](http://www.github.com/hong-sh)
* [Dokyoon Yoon](http://www.github.com/ERU1206)
* Sungkwon On
* [Jiho Yeo](http://www.github.com/jihoyeo)
* [Hyeonhoon Lee](http://www.github.com/HyeonhoonLee)
* [Donggu Kang](http://www.github.com/HERIUN)
* [Sohyeon Yim](http://www.github.com/sohyunwriter)